{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "homework_part2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmitrii-davidov/ysda-deep-learning/blob/spring2019/homework02/homework_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "qirJRPYD5fyd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Homework 2.2: The Quest For A Better Network\n",
        "\n",
        "In this assignment you will build a monster network to solve Tiny ImageNet image classification.\n",
        "\n",
        "This notebook is intended as a sequel to seminar 3, please give it a try if you haven't done so yet."
      ]
    },
    {
      "metadata": {
        "id": "a7-ytD1O5fyr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "(please read it at least diagonally)\n",
        "\n",
        "* The ultimate quest is to create a network that has as high __accuracy__ as you can push it.\n",
        "* There is a __mini-report__ at the end that you will have to fill in. We recommend reading it first and filling it while you iterate.\n",
        " \n",
        "## Grading\n",
        "* starting at zero points\n",
        "* +20% for describing your iteration path in a report below.\n",
        "* +20% for building a network that gets above 20% accuracy\n",
        "* +10% for beating each of these milestones on __TEST__ dataset:\n",
        "    * 25% (50% points)\n",
        "    * 30% (60% points)\n",
        "    * 32.5% (70% points)\n",
        "    * 35% (80% points)\n",
        "    * 37.5% (90% points)\n",
        "    * 40% (full points)\n",
        "    \n",
        "## Restrictions\n",
        "* Please do NOT use pre-trained networks for this assignment until you reach 40%.\n",
        " * In other words, base milestones must be beaten without pre-trained nets (and such net must be present in the anytask atttachments). After that, you can use whatever you want.\n",
        "* you __can't__ do anything with validation data apart from running the evaluation procedure. Please, split train images on train and validation parts\n",
        "\n",
        "## Tips on what can be done:\n",
        "\n",
        "\n",
        " * __Network size__\n",
        "   * MOAR neurons, \n",
        "   * MOAR layers, ([torch.nn docs](http://pytorch.org/docs/master/nn.html))\n",
        "\n",
        "   * Nonlinearities in the hidden layers\n",
        "     * tanh, relu, leaky relu, etc\n",
        "   * Larger networks may take more epochs to train, so don't discard your net just because it could didn't beat the baseline in 5 epochs.\n",
        "\n",
        "   * Ph'nglui mglw'nafh Cthulhu R'lyeh wgah'nagl fhtagn!\n",
        "\n",
        "\n",
        "### The main rule of prototyping: one change at a time\n",
        "   * By now you probably have several ideas on what to change. By all means, try them out! But there's a catch: __never test several new things at once__.\n",
        "\n",
        "\n",
        "### Optimization\n",
        "   * Training for 100 epochs regardless of anything is probably a bad idea.\n",
        "   * Some networks converge over 5 epochs, others - over 500.\n",
        "   * Way to go: stop when validation score is 10 iterations past maximum\n",
        "   * You should certainly use adaptive optimizers\n",
        "     * rmsprop, nesterov_momentum, adam, adagrad and so on.\n",
        "     * Converge faster and sometimes reach better optima\n",
        "     * It might make sense to tweak learning rate/momentum, other learning parameters, batch size and number of epochs\n",
        "   * __BatchNormalization__ (nn.BatchNorm2d) for the win!\n",
        "     * Sometimes more batch normalization is better.\n",
        "   * __Regularize__ to prevent overfitting\n",
        "     * Add some L2 weight norm to the loss function, PyTorch will do the rest\n",
        "       * Can be done manually or like [this](https://discuss.pytorch.org/t/simple-l2-regularization/139/2).\n",
        "     * Dropout (`nn.Dropout`) - to prevent overfitting\n",
        "       * Don't overdo it. Check if it actually makes your network better\n",
        "   \n",
        "### Convolution architectures\n",
        "   * This task __can__ be solved by a sequence of convolutions and poolings with batch_norm and ReLU seasoning, but you shouldn't necessarily stop there.\n",
        "   * [Inception family](https://hacktilldawn.com/2016/09/25/inception-modules-explained-and-implemented/), [ResNet family](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035?gi=9018057983ca), [Densely-connected convolutions (exotic)](https://arxiv.org/abs/1608.06993), [Capsule networks (exotic)](https://arxiv.org/abs/1710.09829)\n",
        "   * Please do try a few simple architectures before you go for resnet-152.\n",
        "   * Warning! Training convolutional networks can take long without GPU. That's okay.\n",
        "     * If you are CPU-only, we still recomment that you try a simple convolutional architecture\n",
        "     * a perfect option is if you can set it up to run at nighttime and check it up at the morning.\n",
        "     * Make reasonable layer size estimates. A 128-neuron first convolution is likely an overkill.\n",
        "     * __To reduce computation__ time by a factor in exchange for some accuracy drop, try using __stride__ parameter. A stride=2 convolution should take roughly 1/4 of the default (stride=1) one.\n",
        " \n",
        "   \n",
        "### Data augmemntation\n",
        "   * getting 5x as large dataset for free is a great \n",
        "     * Zoom-in+slice = move\n",
        "     * Rotate+zoom(to remove black stripes)\n",
        "     * Add Noize (gaussian or bernoulli)\n",
        "   * Simple way to do that (if you have PIL/Image): \n",
        "     * ```from scipy.misc import imrotate,imresize```\n",
        "     * and a few slicing\n",
        "     * Other cool libraries: cv2, skimake, PIL/Pillow\n",
        "   * A more advanced way is to use torchvision transforms:\n",
        "    ```\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "    trainset = torchvision.datasets.ImageFolder(root=path_to_tiny_imagenet, train=True, download=True, transform=transform_train)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "    ```\n",
        "   * Or use this tool from Keras (requires theano/tensorflow): [tutorial](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html), [docs](https://keras.io/preprocessing/image/)\n",
        "   * Stay realistic. There's usually no point in flipping dogs upside down as that is not the way you usually see them.\n",
        "   \n"
      ]
    },
    {
      "metadata": {
        "id": "Ka8fHvd-5fy1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import torch, torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from torch.autograd import Variable\n",
        "from torchsummary import summary\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "36y11ICM5fzK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "c3fb31e7-dcc8-4eb3-9f95-da3096196c58"
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/yandexdataschool/Practical_DL/spring2019/week03_convnets/tiny_img.py -O tiny_img.py\n",
        "\n",
        "from tiny_img import download_tinyImg200\n",
        "data_path = '.'\n",
        "download_tinyImg200(data_path)\n",
        "dataset = torchvision.datasets.ImageFolder('tiny-imagenet-200/train', transform=transforms.ToTensor())\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [80000, 20000])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-16 09:54:49--  https://raw.githubusercontent.com/yandexdataschool/Practical_DL/spring2019/week03_convnets/tiny_img.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3378 (3.3K) [text/plain]\n",
            "Saving to: ‘tiny_img.py’\n",
            "\n",
            "\rtiny_img.py           0%[                    ]       0  --.-KB/s               \rtiny_img.py         100%[===================>]   3.30K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-16 09:54:49 (73.3 MB/s) - ‘tiny_img.py’ saved [3378/3378]\n",
            "\n",
            "./tiny-imagenet-200.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PxliQHHz9Cq4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# a special module that converts [batch, channel, w, h] to [batch, units]\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i3_sl3XK5fzk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 50\n",
        "train_batch_gen = torch.utils.data.DataLoader(train_dataset, \n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=1)\n",
        "val_batch_gen = torch.utils.data.DataLoader(val_dataset,\n",
        "                                            batch_size=batch_size,\n",
        "                                            shuffle=True,\n",
        "                                            num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lPYe5XjP9NU-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_loss(X_batch, y_batch):\n",
        "    X_batch = Variable(torch.FloatTensor(X_batch)).cuda()\n",
        "    y_batch = Variable(torch.LongTensor(y_batch)).cuda()\n",
        "    logits = model.cuda()(X_batch)\n",
        "    return F.cross_entropy(logits, y_batch).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eCdy87Oy5fz3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "b50fe877-1914-4480-bfcd-c0b7daabfbc9"
      },
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Conv2d(3, 32, kernel_size=5),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.ReLU(),\n",
        "    \n",
        "    nn.Conv2d(32, 128, kernel_size=5),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.ReLU(),\n",
        "    \n",
        "    nn.Conv2d(128, 256, kernel_size=3),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.ReLU(),\n",
        "    \n",
        "    nn.Conv2d(256, 1024, kernel_size=1),\n",
        "    nn.BatchNorm2d(1024),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.ReLU(),\n",
        "    \n",
        "    Flatten(),\n",
        "    \n",
        "    nn.Linear(4096, 4096),\n",
        "    nn.Dropout(0.40),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(4096),\n",
        "    \n",
        "    nn.Linear(4096, 200),\n",
        ")\n",
        "\n",
        "summary(model.cuda(), (3, 64, 64), 1)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [1, 32, 60, 60]           2,432\n",
            "       BatchNorm2d-2            [1, 32, 60, 60]              64\n",
            "         MaxPool2d-3            [1, 32, 30, 30]               0\n",
            "              ReLU-4            [1, 32, 30, 30]               0\n",
            "            Conv2d-5           [1, 128, 26, 26]         102,528\n",
            "       BatchNorm2d-6           [1, 128, 26, 26]             256\n",
            "         MaxPool2d-7           [1, 128, 13, 13]               0\n",
            "              ReLU-8           [1, 128, 13, 13]               0\n",
            "            Conv2d-9           [1, 256, 11, 11]         295,168\n",
            "      BatchNorm2d-10           [1, 256, 11, 11]             512\n",
            "        MaxPool2d-11             [1, 256, 5, 5]               0\n",
            "             ReLU-12             [1, 256, 5, 5]               0\n",
            "           Conv2d-13            [1, 1024, 5, 5]         263,168\n",
            "      BatchNorm2d-14            [1, 1024, 5, 5]           2,048\n",
            "        MaxPool2d-15            [1, 1024, 2, 2]               0\n",
            "             ReLU-16            [1, 1024, 2, 2]               0\n",
            "          Flatten-17                  [1, 4096]               0\n",
            "           Linear-18                  [1, 4096]      16,781,312\n",
            "          Dropout-19                  [1, 4096]               0\n",
            "             ReLU-20                  [1, 4096]               0\n",
            "      BatchNorm1d-21                  [1, 4096]           8,192\n",
            "           Linear-22                   [1, 200]         819,400\n",
            "================================================================\n",
            "Total params: 18,275,080\n",
            "Trainable params: 18,275,080\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.05\n",
            "Forward/backward pass size (MB): 5.03\n",
            "Params size (MB): 69.71\n",
            "Estimated Total Size (MB): 74.79\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M1q2ZxHw5f0H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1605
        },
        "outputId": "c432a732-4e9c-4a6e-db9d-68ea7f64cda3"
      },
      "cell_type": "code",
      "source": [
        "opt = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "history = {\n",
        "    'train_loss': [],\n",
        "    'val_acc': [],\n",
        "}\n",
        "\n",
        "def plot_history(name):\n",
        "    plt.plot(np.arange(len(history[name])), history[name], label=name)\n",
        "\n",
        "num_epochs = 16 # total amount of full passes over training data\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time()\n",
        "    train_loss = []\n",
        "    \n",
        "    model.train(True) # enable dropout / batch_norm training behavior\n",
        "    for (X_batch, y_batch) in train_batch_gen:\n",
        "        # train on batch\n",
        "        loss = compute_loss(X_batch, y_batch)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "        train_loss.append(loss.cpu().data.numpy())\n",
        "        \n",
        "    train_loss = np.mean(train_loss)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    \n",
        "    val_acc = []\n",
        "    \n",
        "    model.train(False) # disable dropout / use averages for batch_norm\n",
        "    for X_batch, y_batch in val_batch_gen:\n",
        "        logits = model(Variable(torch.FloatTensor(X_batch)).cuda())\n",
        "        y_pred = logits.max(1)[1].data\n",
        "        val_acc.append(np.mean((y_batch.cpu() == y_pred.cpu()).numpy()))\n",
        "    \n",
        "    val_acc = np.mean(val_acc) * 100\n",
        "    history['val_acc'].append(val_acc)\n",
        "    \n",
        "    clear_output()\n",
        "    \n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plot_history('train_loss')\n",
        "    plot_history('val_acc')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    # Then we print the results for this epoch:\n",
        "    print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, \n",
        "                                               time.time() - start_time))\n",
        "    print(\"\\ttraining loss:\\t\\t\\t{:.6f}\".format(train_loss))\n",
        "    print(\"\\tvalidation accuracy: \\t\\t{:.2f} %\".format(val_acc))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk4AAAJNCAYAAADHzfpbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJwAAgEj/DyLzPIankh42AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14 of 16 took 88.142s\n",
            "\ttraining loss:\t\t\t2.839079\n",
            "\tvalidation accuracy: \t\t28.57 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-28c8698c73d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# disable dropout / use averages for batch_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_batch_gen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# need to call `.task_done()` because we don't use `.join()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "NLUH8W0z5f0S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When everything is done, please calculate accuracy on `tiny-imagenet-200/val`"
      ]
    },
    {
      "metadata": {
        "id": "0qfKSu7R5f0Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_accuracy = .... # YOUR CODE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DMubWpC65f0t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Final results:\")\n",
        "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
        "    test_accuracy * 100))\n",
        "\n",
        "if test_accuracy * 100 > 40:\n",
        "    print(\"Achievement unlocked: 110lvl Warlock!\")\n",
        "elif test_accuracy * 100 > 35:\n",
        "    print(\"Achievement unlocked: 80lvl Warlock!\")\n",
        "elif test_accuracy * 100 > 30:\n",
        "    print(\"Achievement unlocked: 70lvl Warlock!\")\n",
        "elif test_accuracy * 100 > 25:\n",
        "    print(\"Achievement unlocked: 60lvl Warlock!\")\n",
        "else:\n",
        "    print(\"We need more magic! Follow instructons below\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6874_KBm5f1H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "# Report\n",
        "\n",
        "All creative approaches are highly welcome, but at the very least it would be great to mention\n",
        "* the idea;\n",
        "* brief history of tweaks and improvements;\n",
        "* what is the final architecture and why?\n",
        "* what is the training method and, again, why?\n",
        "* Any regularizations and other techniques applied and their effects;\n",
        "\n",
        "\n",
        "There is no need to write strict mathematical proofs (unless you want to).\n",
        " * \"I tried this, this and this, and the second one turned out to be better. And i just didn't like the name of that one\" - OK, but can be better\n",
        " * \"I have analized these and these articles|sources|blog posts, tried that and that to adapt them to my problem and the conclusions are such and such\" - the ideal one\n",
        " * \"I took that code that demo without understanding it, but i'll never confess that and instead i'll make up some pseudoscientific explaination\" - __not_ok__"
      ]
    },
    {
      "metadata": {
        "id": "ycriyXyi5f1U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Hi, my name is `___ ___`, and here's my story\n",
        "\n",
        "A long time ago in a galaxy far far away, when it was still more than an hour before the deadline, i got an idea:\n",
        "\n",
        "##### I gonna build a neural network, that\n",
        "* brief text on what was\n",
        "* the original idea\n",
        "* and why it was so\n",
        "\n",
        "How could i be so naive?!\n",
        "\n",
        "##### One day, with no signs of warning,\n",
        "This thing has finally converged and\n",
        "* Some explaination about what were the results,\n",
        "* what worked and what didn't\n",
        "* most importantly - what next steps were taken, if any\n",
        "* and what were their respective outcomes\n",
        "\n",
        "##### Finally, after __  iterations, __ mugs of [tea/coffee]\n",
        "* what was the final architecture\n",
        "* as well as training method and tricks\n",
        "\n",
        "That, having wasted ____ [minutes, hours or days] of my life training, got\n",
        "\n",
        "* accuracy on training: __\n",
        "* accuracy on validation: __\n",
        "* accuracy on test: __\n",
        "\n",
        "\n",
        "[an optional afterword and mortal curses on assignment authors]"
      ]
    }
  ]
}